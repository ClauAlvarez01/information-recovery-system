import json
from django.shortcuts import render
from rest_framework.decorators import api_view
from rest_framework.response import Response
import os
from api.trie import Trie
from api.boolean_model import BooleanModel
from api.LSI_model import lsi_model
import spacy
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer


documents = {}
vocabulary = {}
queries = {}
cranfield_docs = {}
docs_per_token = {}


# ~~~~~~~~~~~~~~~~~~~~~~~~ Data paths ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
docs_per_token_path = os.path.join(os.path.dirname(
    os.path.abspath(__file__)), '..', '..', '..', 'data', 'docs_per_token.json')
docs_per_token_path = os.path.abspath(docs_per_token_path)

documents_path = os.path.join(os.path.dirname(
    os.path.abspath(__file__)), '..', '..', '..', 'data', 'documents.json')
documents_path = os.path.abspath(documents_path)

vocabulary_path = os.path.join(os.path.dirname(
    os.path.abspath(__file__)), '..', '..', '..', 'data', 'vocabulary.json')
vocabulary_path = os.path.abspath(vocabulary_path)

cranfield_docs_path = os.path.join(os.path.dirname(
    os.path.abspath(__file__)), '..', '..', '..', 'data', 'cranfieldDoc.json')
cranfield_docs_path = os.path.abspath(cranfield_docs_path)

queries_path = os.path.join(os.path.dirname(
    os.path.abspath(__file__)), '..', '..', '..', 'data', 'querys.json')
queries_path = os.path.abspath(queries_path)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


# ~~~~~~~~~~~~~~~~~~~~~~~~~ Load jsons ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
with open(docs_per_token_path, 'r') as docs_per_token_file:
    docs_per_token = json.load(docs_per_token_file)

with open(documents_path, 'r') as documents_file:
    documents = json.load(documents_file)
documents_values = list(documents['documents'].values())

with open(vocabulary_path, 'r') as vocabulary_file:
    vocabulary = json.load(vocabulary_file)
vocabulary_values = vocabulary['vocabulary']

with open(cranfield_docs_path, 'r') as cranfield_docs_file:
    cranfield_docs = json.load(cranfield_docs_file)

with open(queries_path, 'r') as queries_file:
    queries = json.load(queries_file)
queries_values = queries['querys']
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Models ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
nlp = spacy.load("en_core_web_sm")

trie = Trie(docs_per_token['docs_per_token'])
boolean_model = BooleanModel(nlp, trie)


vectorizer = TfidfVectorizer(vocabulary=vocabulary_values)
matrix, lsa_model = lsi_model(documents_values, vectorizer)
# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


# http://localhost:8000/api/queries
@api_view(['GET'])
def queries(request):
    data = []

    print(len(queries_values.items()))
    for query_id, text_list in queries_values.items():
        text = text_list[0]
        data.append({
            "query_id": query_id,
            "text": text
        })


    print(data)
    print("se printeo la data")
    return Response({'data': data})


# http://localhost:8000/api/test
@api_view(['GET'])
def test(request):
    docs = [
        {
            'doc_id': '1',
            'title': 'T칤tulo del Documento 1',
            'text': 'Texto del Documento 1. Este es un ejemplo de un texto m치s extenso para el Documento 1. Puede contener informaci칩n detallada y relevante.',
            'author': 'Autor 1',
            'bib': 'Bibliograf칤a 1'
        },
        {
            'doc_id': '2',
            'title': 'T칤tulo del Documento 2',
            'text': 'Texto del Documento 2. Aqu칤 hay m치s contenido para el Documento 2. Puede incluir detalles, ejemplos y cualquier informaci칩n adicional que sea necesaria.',
            'author': 'Autor 2',
            'bib': 'Bibliograf칤a 2'
        },
        {
            'doc_id': '3',
            'title': 'T칤tulo del Documento 3',
            'text': 'Texto del Documento 3. Este documento tiene un texto m치s extenso que aborda varios temas importantes. Puede contener secciones y subsecciones.',
            'author': 'Autor 3',
            'bib': 'Bibliograf칤a 3'
        },
        {
            'doc_id': '4',
            'title': 'T칤tulo del Documento 4',
            'text': 'Texto del Documento 4. En este documento, se discuten diversas ideas y conceptos. Se proporcionan ejemplos y an치lisis detallados.',
            'author': 'Autor 4',
            'bib': 'Bibliograf칤a 4'
        },
        {
            'doc_id': '5',
            'title': 'T칤tulo del Documento 5',
            'text': 'Texto del Documento 5. Aqu칤 encontrar치s una amplia gama de informaci칩n relacionada con el tema principal. El autor ofrece insights y conclusiones.',
            'author': 'Autor 5',
            'bib': 'Bibliograf칤a 5'
        },
        {
            'doc_id': '6',
            'title': 'T칤tulo del Documento 6',
            'text': 'Texto del Documento 6. Este documento explora aspectos espec칤ficos y proporciona datos detallados. Puede ser de inter칠s para expertos en el campo.',
            'author': 'Autor 6',
            'bib': 'Bibliograf칤a 6'
        },
        {
            'doc_id': '7',
            'title': 'T칤tulo del Documento 7',
            'text': 'Texto del Documento 7. Aqu칤 se presentan casos de estudio y ejemplos pr치cticos. El autor analiza y extrae lecciones valiosas de cada situaci칩n.',
            'author': 'Autor 7',
            'bib': 'Bibliograf칤a 7'
        },
        {
            'doc_id': '8',
            'title': 'T칤tulo del Documento 8',
            'text': 'Texto del Documento 8. Este documento se centra en investigaciones recientes y descubrimientos. Proporciona una visi칩n actualizada del estado del campo.',
            'author': 'Autor 8',
            'bib': 'Bibliograf칤a 8'
        },
        {
            'doc_id': '9',
            'title': 'T칤tulo del Documento 9',
            'text': 'Texto del Documento 9. Aqu칤 se abordan controversias y debates en el campo. El autor presenta diferentes perspectivas y argumentos.',
            'author': 'Autor 9',
            'bib': 'Bibliograf칤a 9'
        },
        {
            'doc_id': '10',
            'title': 'T칤tulo del Documento 10',
            'text': 'Texto del Documento 10. Este documento sirve como una revisi칩n exhaustiva de la literatura existente. El autor destaca tendencias y brechas en la investigaci칩n.',
            'author': 'Autor 10',
            'bib': 'Bibliograf칤a 10'
        }
    ]
    metrics = {
        'precision': {
            'boolean': '0.57',
            'other': '0.90'
        },
        'recovered': {
            'boolean': '0.20',
            'other': '0.46'
        },
        'f1': {
            'boolean': '0.39',
            'other': '0.49'
        },
        'fallout': {
            'boolean': '0.31',
            'other': '0.41'
        }
    }

    return Response({'docs': docs, 'metrics': metrics})

@api_view(['GET'])
def search(request):
    query = request.GET.get('query', '')
    query = query.lower()

    query_vector = vectorizer.transform([query])
    semantic_query = lsa_model.transform(query_vector)

    similarity = cosine_similarity(semantic_query, matrix)
    similar_indexes = similarity.argsort()[0][-10:][::-1]
    similar_indexes = [i+1 for i in similar_indexes]

    docs = []
    cranfield_docs_values = list(cranfield_docs['cranfieldDoc'].values())

    for i in similar_indexes:
        docs.append(cranfield_docs_values[i])


    # 游뚿游뚿游뚿游뚿游뚿游뚿游뚿游뚿游뚿游뚿游뚿游뚿游뚿游뚿游뚿游뚿游뚿游뚿
    metrics = {
        'precision': {
            'boolean': '0.57',
            'other': '0.90'
        },
        'recovered': {
            'boolean': '0.20',
            'other': '0.46'
        },
        'f1': {
            'boolean': '0.39',
            'other': '0.49'
        },
        'fallout': {
            'boolean': '0.31',
            'other': '0.41'
        }
    }

    return Response({'docs': docs, 'metrics': metrics})
